<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Self-Supervised Learning | Sterling Archer</title> <meta name="author" content="Sterling Archer"> <meta name="description" content="A type of machine learning in which an algorithm learns to perform a task without being explicitly given labels or examples of the task."> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700%7CRoboto+Slab:100,300,400,500,700%7CMaterial+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/blist-logo.png"> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://archersterling007.github.io/Blog/2023/Self-Supervised_Learning/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js"></script> <script src="/assets/js/dark_mode.js"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Sterling </span>Archer</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About</a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">Blog</a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">Projects</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">Self-Supervised Learning</h1> <p class="post-meta">January 9, 2023• ABDALLAH YOUBI IDRISSI</p> <p class="post-tags"> <a href="/blog/2023"> <i class="fas fa-calendar fa-sm"></i> 2023 </a>   ·   <a href="/blog/tag/self-supervised-learning"> <i class="fas fa-hashtag fa-sm"></i> Self-Supervised Learning</a>   </p> </header> <article class="post-content"> <h2 id="courses">Courses</h2> <ul> <li> <a href="https://self-supervised.cs.jhu.edu/fa2022/index.html" rel="external nofollow noopener" target="_blank">CSCI 601.771: Self-supervised Statistical Models</a> - <a href="https://self-supervised.cs.jhu.edu/sp2023/" rel="external nofollow noopener" target="_blank">Spring 2023</a> </li> <li>CIS 620 - Learning in Few-Labels Settings - <a href="https://www.seas.upenn.edu/~cis6200/" rel="external nofollow noopener" target="_blank">Website</a> </li> <li>COMP 152 Machine Learning with Limited Annotation - <a href="https://berthuang.com/courses/limited21/" rel="external nofollow noopener" target="_blank">Website</a> </li> <li><a href="https://www.youtube.com/playlist?list=PLd9i_xMMzZF7QiPZNF7zblpTksTt0DDy6" rel="external nofollow noopener" target="_blank">Self-Supervised Learning by Anuj shah</a></li> <li> <a href="https://www.youtube.com/playlist?list=PLLHTzKZzVU9f3kmEta5dlkMXgtD1LxHzT" rel="external nofollow noopener" target="_blank">Joint Embedding Methods - NYU Deep Learning SP22</a> and <a href="https://atcold.github.io/NYU-DLSP21/en/week15/15/" rel="external nofollow noopener" target="_blank">Lecture Notes</a> </li> </ul> <h2 id="energy-based-models-and-energy-based-self-supervised-learning">Energy Based Models and Energy-Based Self-Supervised Learning</h2> <ul> <li>Theory and Application of Energy-Based Generative Models, CVPR 2021 Tutorial - <a href="https://energy-based-models.github.io/#Topics" rel="external nofollow noopener" target="_blank">Website</a> and <a href="https://www.youtube.com/playlist?list=PLR5rf_74feHp-VUvA83j9h0muFR7Wnz4r" rel="external nofollow noopener" target="_blank">Lectures</a> </li> <li>Collection of research materials on EBM/EBL (Energy Based Models, Energy Based Learning) - <a href="https://github.com/yataobian/awesome-ebm" rel="external nofollow noopener" target="_blank">GitHub repo</a> </li> <li>Chunpai Wang notes: <ul> <li><a href="https://chunpai.github.io/assets/note/Energy_and_Probability.pdf" rel="external nofollow noopener" target="_blank">Energy and Probability</a></li> <li><a href="https://chunpai.github.io/assets/note/Boltzmann_Machines.pdf" rel="external nofollow noopener" target="_blank">Boltzmann Machines</a></li> <li><a href="https://chunpai.github.io/assets/note/EBM_3__Non_probabilistic_Energy_Based_Learning.pdf" rel="external nofollow noopener" target="_blank">Training and Inference</a></li> </ul> </li> <li><a href="https://physicsofebm.github.io/" rel="external nofollow noopener" target="_blank">The Physics of Energy-Based Models</a></li> <li><a href="http://yann.lecun.com/exdb/publis/pdf/lecun-06.pdf" rel="external nofollow noopener" target="_blank">A Tutorial on Energy-Based Learning</a></li> <li><a href="https://arxiv.org/abs/2101.03288" rel="external nofollow noopener" target="_blank">How to Train Your Energy-Based Models by Yang Song, Diederik P. Kingma</a></li> <li><a href="https://arxiv.org/abs/1708.06008" rel="external nofollow noopener" target="_blank">Boltzmann machines and energy-based models by Takayuki Osogami</a></li> <li> <a href="https://arxiv.org/pdf/1811.02486.pdf" rel="external nofollow noopener" target="_blank">Concept Learning with Energy-Based Models</a> and <a href="https://openai.com/blog/learning-concepts-with-energy-functions/" rel="external nofollow noopener" target="_blank">OpenAI Blog Post</a> and <a href="https://www.youtube.com/watch?v=Cs_j-oNwGgg" rel="external nofollow noopener" target="_blank">Yannic’s Explanation</a> </li> <li><a href="https://arxiv.org/abs/1912.00589" rel="external nofollow noopener" target="_blank">Flow Contrastive Estimation of Energy-Based Models</a></li> <li><a href="https://arxiv.org/pdf/2006.08205.pdf" rel="external nofollow noopener" target="_blank">Learning Latent Space Energy-Based Prior Model</a></li> <li><a href="https://arxiv.org/pdf/1812.10907.pdf" rel="external nofollow noopener" target="_blank">Divergence Triangle for Joint Training of Generator Model, Energy-based Model, and Inference Model</a></li> <li><a href="https://arxiv.org/pdf/2006.06059.pdf" rel="external nofollow noopener" target="_blank">Joint Training of Variational Auto-Encoder and Latent Energy-Based Model</a></li> <li><a href="https://arxiv.org/abs/2106.13798" rel="external nofollow noopener" target="_blank">Conjugate Energy-Based Models</a></li> <li> <p><a href="https://sslneurips22.github.io/paper_pdfs/paper_49.pdf" rel="external nofollow noopener" target="_blank">Guiding Energy-based Models via Contrastive Latent Variables</a></p> </li> <li>Alfredo Canziani Lectures: <ul> <li>Energy-Based Self-Supervised Learning - <a href="https://www.youtube.com/watch?v=bDvpuaPq8Vc" rel="external nofollow noopener" target="_blank">Lecture</a> </li> <li><a href="https://www.youtube.com/playlist?list=PLLHTzKZzVU9f3kmEta5dlkMXgtD1LxHzT" rel="external nofollow noopener" target="_blank">Joint Embedding Methods (JEMs) NYU Deep Learning SP22</a></li> <li><a href="https://www.youtube.com/playlist?list=PLLHTzKZzVU9d_3TcHbyiAjl5qCbpJR-o0" rel="external nofollow noopener" target="_blank">NYU Deep Learning FL22</a></li> <li>NYU Deep Learning SP21 - <a href="https://atcold.github.io/NYU-DLSP21/" rel="external nofollow noopener" target="_blank">Website</a> and <a href="https://www.youtube.com/playlist?list=PLLHTzKZzVU9e6xUfG10TkTWApKSZCzuBI" rel="external nofollow noopener" target="_blank">Lectures</a> </li> </ul> </li> <li>Yann LeCun Talks: <ul> <li><a href="https://www.youtube.com/watch?v=piaPIKO1MFY" rel="external nofollow noopener" target="_blank">ICLR 2020: Energy-Based Models</a></li> <li><a href="https://iclr.cc/virtual_2020/speaker_7.html" rel="external nofollow noopener" target="_blank">The future is self-supervised</a></li> <li><a href="https://www.youtube.com/watch?v=BqgnnrojVBI" rel="external nofollow noopener" target="_blank">Energy-Based Models for Self-Supervised Learning</a></li> <li><a href="https://www.youtube.com/watch?v=4lthJd3DNTM" rel="external nofollow noopener" target="_blank">The Energy-Based Learning Model</a></li> <li> <a href="https://leshouches2022.github.io/" rel="external nofollow noopener" target="_blank">Summer school on Statistical Physics &amp; Machine learning: From machine learning to autonomous intelligence</a> and <a href="https://www.youtube.com/playlist?list=PLEIq5bchE3R3Yl5taXdYA04a9kH9yvyGm" rel="external nofollow noopener" target="_blank">Youtube Playlist</a> </li> </ul> </li> </ul> <h2 id="visual-representation-learning-and-joint-embedding-methods">Visual Representation Learning and Joint Embedding Methods</h2> <p>Visual Representation Learning trains a system to produce the representations required for feature detection or classification from raw data. Visual Representation Learning is about the representations of images or videos in particular. Self-supervised Visual Representation Learning, can be classified into Generative models, Pretext Tasks and Joint Embedding methods. In generative models, you train the model to reconstruct the original image from the noisy image. In pretext tasks, you train the model to figure out a smart way to generate pseudo labels. Joint Embedding Methods try to make their backbone network robust to certain distortions and are invariant to data augmentation. The pretext task is a self-supervised learning task solved to learn visual representations, with the aim of using the learned representations or model weights obtained in the process, for other downstream tasks. The pretext task is usually performed on a property that is inherent in the dataset itself.</p> <p>Energy Based Models can be classified into Generative or Joint Embedding based on architectures, and into Contrastive or “Architectural &amp; Regularised” based on training methods. The contrastive methods differ in the way they pick the points to push up. While the architectural methods differ in the way they limit the volume of low energy.</p> <p>Joint Embedding Methods (JEMs) training methods can be classified into four types: Contrastive Methods, Non-contrastive Methods, Clustering Methods and Other Methods.</p> <p>Contrastive Methods push positive pairs closer and negative pairs away. Contrastive methods include MoCo, PIRL, and SimCLR. There are other Contrastive Methods such as Contrastive Divergence (or Persistent Contrastive Divergence), Ratio Matching, Noise Contrastive Estimation, and Minimum Probability Flow. Contrastive Methods can be further classified in this way:</p> <ul> <li>Push Up Everywhere (Maximum Likelihood) - This category includes methods that aim to push the representations of all data points as far apart as possible.</li> <li>Push Up at Locations (ML with MCMC Methods, Siamese Neural Networks (MoCo, PIRL, SimCLR), GAN) - This category includes methods that push the representations of certain data points further apart than others. An example of this is the Siamese network, where two versions of the same network are used to process two different data points, and the distance between their representations is minimized for similar data points and maximized for dissimilar data points.</li> <li>Off-manifold to on-manifold (Denoising and Masked AE (BERT)) - This category includes methods that learn to denoise or recover the original data from a corrupted or masked version.</li> </ul> <p>Architectural &amp; Regularised (Non-contrastive) Methods can classified into:</p> <ul> <li>Upper-bound low energy volume (PCA, K-means, GMM) - This category includes methods that aim to find a low-dimensional representation of the data by looking for a subspace that captures the most variation in the data, while keeping the energy of the representation low.</li> <li>Regularization term (Sparse &amp; Contractive AE, LISTA, BYOL, VicReg) - This category includes methods that add a regularization term to the objective function of the model, which encourage certain properties of the learned representation, such as sparsity or contractiveness.</li> <li>Minimise gradient, Maximise curvature (Score Matching)</li> </ul> <p>Non-contrastive methods are based on Information Theory and don’t require special architectures or engineering techniques, for example Barlow Twins and VicReg.</p> <p>Clustering Methods prevent trivial solution by quantizing the embedding space. Clustering Methods include ClusterFit, SwAV, DeepCluster, ProPos, CC and PCL. Other Methods are local and don’t create problem with distributed training unlike previous methods. Examples are Dino, BYOL, SimSiam and Data2Vec.</p> <p>Another classification is the following:</p> <ul> <li>Instance Discrimination (MoCo, SimCLR, BYOL)</li> <li>Clustering and Classification (SwAV, DeepCluster)</li> <li>Others (Solving Jigsaw, Rotation, ReSort, LocationPrediction,GAN)</li> </ul> <p>Sparse Coding is a Regularized Latent Variable Energy Based Model (FISTA, LISTA are algorithms that optimizes the sparse coding energy function.).</p> <h2 id="blog-posts">Blog Posts</h2> <ul> <li> <a href="https://ai.facebook.com/blog/self-supervised-learning-the-dark-matter-of-intelligence/" rel="external nofollow noopener" target="_blank">Self-supervised learning: The dark matter of intelligence</a> and <a href="https://www.youtube.com/watch?v=Ag1bw8MfHGQ" rel="external nofollow noopener" target="_blank">Yannic Kilcher Explanation</a> </li> <li><a href="https://lilianweng.github.io/posts/2019-11-10-self-supervised/" rel="external nofollow noopener" target="_blank">Self-Supervised Representation Learning</a></li> <li><a href="https://github.com/jason718/awesome-self-supervised-learning" rel="external nofollow noopener" target="_blank">A curated list of awesome self-supervised methods</a></li> <li><a href="https://amitness.com/2020/02/illustrated-self-supervised-learning/" rel="external nofollow noopener" target="_blank">The Illustrated Self-Supervised Learning</a></li> <li><a href="https://lilianweng.github.io/posts/2021-05-31-contrastive/" rel="external nofollow noopener" target="_blank">Contrastive Representation Learning</a></li> <li><a href="https://ankeshanand.com/blog/2020/01/26/contrative-self-supervised-learning.html" rel="external nofollow noopener" target="_blank">Contrastive Self-Supervised Learning</a></li> <li><a href="https://towardsdatascience.com/self-supervised-learning-ssl-overview-8a7f24740e40" rel="external nofollow noopener" target="_blank">Self-Supervised Learning (SSL) Overview</a></li> </ul> <h2 id="papers">Papers</h2> <ul> <li> <p><a href="https://openreview.net/pdf?id=BZ5a1r-kVsf" rel="external nofollow noopener" target="_blank">A Path Towards Autonomous Machine Intelligence</a>, <a href="https://www.youtube.com/watch?v=VRzvpV9DZ8Y&amp;t=16s" rel="external nofollow noopener" target="_blank">Talk</a>, <a href="https://ai.facebook.com/blog/yann-lecun-advances-in-ai-research/" rel="external nofollow noopener" target="_blank">Blog Post</a> and <a href="https://www.youtube.com/watch?v=jSdHmImyUjk" rel="external nofollow noopener" target="_blank">Yannic Kilcher Explanation</a></p> </li> <li>Self-Supervised Learning Theory: <ul> <li><a href="https://arxiv.org/abs/2207.10081" rel="external nofollow noopener" target="_blank">What Do We Maximize in Self-Supervised Learning?</a></li> <li><a href="https://arxiv.org/abs/2202.04933" rel="external nofollow noopener" target="_blank">Energy-Based Contrastive Learning of Visual Representations</a></li> <li><a href="https://arxiv.org/abs/2206.02574" rel="external nofollow noopener" target="_blank">On the duality between contrastive and non-contrastive self-supervised learning</a></li> <li><a href="https://arxiv.org/abs/2010.05113" rel="external nofollow noopener" target="_blank">Contrastive Representation Learning: A Framework and Review</a></li> <li> <a href="https://arxiv.org/abs/2205.11508" rel="external nofollow noopener" target="_blank">Contrastive and Non-Contrastive Self-Supervised Learning Recover Global and Local Spectral Embedding Methods</a> and <a href="https://openreview.net/attachment?id=jQgsZDspz5h&amp;name=supplementary_material" rel="external nofollow noopener" target="_blank">Appendix</a> </li> <li><a href="https://arxiv.org/abs/2209.14884" rel="external nofollow noopener" target="_blank">Joint Embedding Self-Supervised Learning in the Kernel Regime</a></li> <li><a href="https://arxiv.org/abs/2006.05576" rel="external nofollow noopener" target="_blank">Demystifying Self-Supervised Learning: An Information-Theoretical Framework</a></li> <li><a href="https://arxiv.org/abs/2006.08218" rel="external nofollow noopener" target="_blank">Self-supervised Learning: Generative or Contrastive</a></li> <li><a href="https://arxiv.org/abs/2111.00743" rel="external nofollow noopener" target="_blank">Towards the Generalization of Contrastive Self-Supervised Learning</a></li> </ul> </li> <li>Self-Supervised Learning Methods: <ul> <li><a href="https://arxiv.org/abs/2211.10831" rel="external nofollow noopener" target="_blank">JEPA: Joint Embedding Predictive Architectures Focus on Slow Features</a></li> <li><a href="https://arxiv.org/abs/2106.11230" rel="external nofollow noopener" target="_blank">IFM: Can contrastive learning avoid shortcut solutions?</a></li> <li><a href="https://arxiv.org/abs/2002.05709" rel="external nofollow noopener" target="_blank">SimCLR: A Simple Framework for Contrastive Learning of Visual Representations</a></li> <li><a href="https://arxiv.org/abs/2105.04906" rel="external nofollow noopener" target="_blank">VICREG: VARIANCE-INVARIANCE-COVARIANCE RE- GULARIZATION FOR SELF-SUPERVISED LEARNING</a></li> <li><a href="https://arxiv.org/abs/2006.09882" rel="external nofollow noopener" target="_blank">SwAV: Unsupervised Learning of Visual Features by Contrasting Cluster Assignments</a></li> <li><a href="https://arxiv.org/abs/1807.05520" rel="external nofollow noopener" target="_blank">DeepCluster: Deep Clustering for Unsupervised Learning of Visual Features</a></li> <li><a href="https://arxiv.org/abs/1911.05722" rel="external nofollow noopener" target="_blank">Moco: Momentum Contrast for Unsupervised Visual Representation Learning</a></li> <li><a href="https://arxiv.org/abs/1912.01991" rel="external nofollow noopener" target="_blank">PIRL: Self-Supervised Learning of Pretext-Invariant Representations</a></li> <li><a href="https://arxiv.org/abs/1912.03330" rel="external nofollow noopener" target="_blank">ClusterFit: Improving Generalization of Visual Representations</a></li> <li><a href="https://arxiv.org/abs/2103.03230" rel="external nofollow noopener" target="_blank">Barlow Twins: Self-Supervised Learning via Redundancy Reduction</a></li> <li><a href="https://arxiv.org/abs/2007.06346" rel="external nofollow noopener" target="_blank">W-MSE: Whitening for Self-Supervised Representation Learning</a></li> <li><a href="https://arxiv.org/abs/2206.10698" rel="external nofollow noopener" target="_blank">TiCo: Transformation Invariance and Covariance Contrast for Self-Supervised Visual Representation Learning</a></li> <li><a href="https://arxiv.org/abs/2011.10566" rel="external nofollow noopener" target="_blank">SimSiam: Exploring Simple Siamese Representation Learning</a></li> <li><a href="https://arxiv.org/abs/2111.11821" rel="external nofollow noopener" target="_blank">ProPos: Learning Representation for Clustering via Prototype Scattering and Positive Sampling</a></li> <li><a href="https://arxiv.org/abs/2009.09687" rel="external nofollow noopener" target="_blank">CC: Contrastive Clustering</a></li> <li><a href="https://arxiv.org/abs/2006.07733" rel="external nofollow noopener" target="_blank">BYOL: Bootstrap your own latent: A new approach to self-supervised Learning</a></li> <li><a href="https://arxiv.org/abs/2005.04966" rel="external nofollow noopener" target="_blank">PCL: Prototypical Contrastive Learning of Unsupervised Representations</a></li> <li><a href="https://arxiv.org/abs/2104.14294" rel="external nofollow noopener" target="_blank">Dino: Emerging Properties in Self-Supervised Vision Transformers</a></li> <li><a href="https://arxiv.org/abs/2202.03555" rel="external nofollow noopener" target="_blank">Data2vec: A General Framework for Self-supervised Learning in Speech, Vision and Language</a></li> <li><a href="https://arxiv.org/abs/2210.02885" rel="external nofollow noopener" target="_blank">RankMe: Assessing the downstream performance of pretrained self-supervised representations by their rank</a></li> <li><a href="https://arxiv.org/abs/2210.01571" rel="external nofollow noopener" target="_blank">VICRegL: Self-Supervised Learning of Local Visual Features</a></li> <li><a href="https://arxiv.org/abs/2103.11275" rel="external nofollow noopener" target="_blank">RPC: Self-supervised Representation Learning with Relative Predictive Coding</a></li> <li><a href="https://arxiv.org/abs/1807.03748" rel="external nofollow noopener" target="_blank">CPC: Representation Learning with Contrastive Predictive Coding</a></li> <li><a href="https://arxiv.org/abs/2209.14905" rel="external nofollow noopener" target="_blank">VCReg: Variance Covariance Regularization Enforces Pairwise Independence in Self-Supervised Representations</a></li> <li><a href="https://arxiv.org/abs/2110.06848" rel="external nofollow noopener" target="_blank">DCL: Decoupled Contrastive Learning</a></li> <li><a href="https://arxiv.org/abs/2110.09348" rel="external nofollow noopener" target="_blank">DirectCLR: Understanding Dimensional Collapse in Contrastive Self-supervised Learning</a></li> </ul> </li> </ul> <h2 id="libraries">Libraries</h2> <ul> <li><a href="https://vissl.ai/" rel="external nofollow noopener" target="_blank">A library for state-of-the-art self-supervised learning from images</a></li> </ul> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2023 Sterling Archer. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="/assets/js/common.js"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>