---
layout: post
title: "Natural Language Processing"
date: 2022-12-26T21:28:26+01:00
author: "ABDALLAH YOUBI IDRISSI"
description: "A field of computer science and artificial intelligence concerned with enabling computers to understand, interpret, and generate human language."
tags: ["Natural Language Processing"]
---

## Learning Material

### Books

- [Speech and Language Processing by Daniel Jurafsky and James H. Martin](https://web.stanford.edu/~jurafsky/slp3/)
- [Introduction to Natural Language Processing by Jacob Eisenstein](https://mitpress.mit.edu/9780262042840/), [November 13, 2018 Draft](https://cseweb.ucsd.edu/~nnakashole/teaching/eisenstein-nov18.pdf) and [Other Material](https://github.com/jacobeisenstein/gt-nlp-class)
- [Natural Language Processing with Transformers Book](https://transformersbook.com/)
- [Linguistic Structure Prediction by Noah A. Smith](http://www.cs.cmu.edu/~nasmith/LSP/)

### Courses

- Harvard CS197: AI Research Experiences â€“ [Website](https://www.cs197.seas.harvard.edu/), [Course Book](https://docs.google.com/document/d/1uvAbEhbgS_M-uDMTzmOWRlYxqCkogKRXdbKYYT98ooc/edit#)
- Stanford University Courses:
  - CS224U: Natural Language Understanding - [Website](http://web.stanford.edu/class/cs224u/) and [Lectures](https://www.youtube.com/playlist?list=PLoROMvodv4rPt5D0zs3YhbWSZA8Q_DyiJ)
  - CS224N: Natural Language Processing with Deep Learrning - [Website](http://web.stanford.edu/class/cs224n/) and [Spring 2021 Lectures](https://www.youtube.com/playlist?list=PLoROMvodv4rOhcuXMZkNm7j3fVwBBY42z)
  - CS25: Transformers United - [2023](https://web.stanford.edu/class/cs25/) - [2021](https://web.stanford.edu/class/cs25/prev_years/2021_fall/) and [Lectures](https://www.youtube.com/playlist?list=PLoROMvodv4rNiJRchCzutFw5ItR_Z27CM)
  - CS324 - Large Language Models - [Website](https://stanford-cs324.github.io/winter2022/)
- CIS 700 - Reasoning for Natural Language Understanding - [Website](https://www.seas.upenn.edu/~cis7000a/Spring20/)
- CMU CS 11-711, Fall 2022 Advanced NLP - [Website](http://www.phontron.com/class/anlp2022/index.html) and [Lectures](https://www.youtube.com/playlist?list=PL8PYTP1V4I8D0UkqW2fEhgLrnlDW9QK7z)
- CMU 10-418/10-618  Machine Learning for Structured Data:
  - Fall 2019 - [Website](http://www.cs.cmu.edu/~mgormley/courses/10418-f19/) and [Lectures](https://www.youtube.com/playlist?list=PL4CxkUJbvNVihRKP4bXufvRLIWzeS-ieP)
  - Fall 2022 - [Website](http://www.cs.cmu.edu/~mgormley/courses/10418/)
- CS 601.471/671 NLP: Self-supervised Models - [2023](https://self-supervised.cs.jhu.edu/sp2023/) and [2022](https://self-supervised.cs.jhu.edu/fa2022/)
- CS 685, Spring 2022 Advanced Natural Language Processing - [Website](https://people.cs.umass.edu/~miyyer/cs685/) and [Lectures](https://www.youtube.com/playlist?list=PLWnsVgP6CzadI4-FT2Po4wsEK7MHCIQ-d)
- COS 597G (Fall 2022): Understanding Large Language Models - [Website](https://www.cs.princeton.edu/courses/archive/fall22/cos597G/)
- Seminar on Large Language Models (COMP790-101 at UNC Chapel Hill, Fall 2022) - [Website](https://github.com/craffel/llm-seminar/)
- Natural Language Processing by Michael Collins, Columbia University - [website](http://www.cs.columbia.edu/~cs4705/) and [Lectures](https://www.bilibili.com/video/av29608234/?from=search&seid=10252913399572988135)
- CE7455: Deep Learning for Natural Language Processing: From Theory to Practice - [Website](https://ntunlpsg.github.io/ce7455_deep-nlp-20/)
- [COMP 445/Ling 445/Ling 645 : Computational Linguistics](https://foundations-computational-linguistics.github.io/) and [Psets](https://github.com/lunadana/C445-Computational-Linguistics)

### Papers

- [paperswithcode](https://paperswithcode.com/area/natural-language-processing)
- [On the Opportunities and Risks of Foundation Models](https://arxiv.org/abs/2108.07258)
- [A Primer on Neural Network Models for Natural Language Processing](https://arxiv.org/pdf/1510.00726.pdf)
- [Natural language processing: state of the art, current trends and challenges](https://link.springer.com/article/10.1007/s11042-022-13428-4)
- [Pre-trained Models for Natural Language Processing: A Survey](https://arxiv.org/abs/2003.08271)

### Tutorials

- A curated list of resources dedicated to Natural Language Processing (NLP) - [First repo](https://github.com/keon/awesome-nlp) and [the second](https://github.com/brianspiering/awesome-dl4nlp)
- [Natural Language Processing Tutorial for Deep Learning Researchers](https://github.com/graykode/nlp-tutorial)
- [A collection of 700+ survey papers on Natural Language Processing (NLP) and Machine Learning (ML)](https://github.com/NiuTrans/ABigSurvey)
- [Latent Structure Models for Natural Language Processing](https://deep-spin.github.io/tutorial/)

### Blog Posts

- [Transformer models: an introduction and catalog](https://amatriain.net/blog/transformer-models-an-introduction-and-catalog-2d1e9039f376/)

### Libraries and Frameworks

- [Hugging Face](https://github.com/huggingface)
- [NTLK: Natural Language Toolkit](https://www.nltk.org/)
- [BertViz: Visualize Attention in NLP Models (BERT, GPT2, BART, etc.)](https://github.com/jessevig/bertviz)

## Architectures

### Transformers

#### Transformers: Papers

- [The O.G. paper, Attention is All You Need](https://proceedings.neurips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf)
- [A Survey of Transformers](https://arxiv.org/abs/2106.04554)

#### Transformers: Blog Posts

- [Introduction to Transformers](https://dair-ai.notion.site/Introduction-to-Transformers-4b869c9595b74f72b088e5f2793ece80) and [Notes from MIT Course](https://dair-ai.notion.site/Lecture-2-RNNs-and-Transformers-71fb3ba2a24f4b6c8cc77281fc19cfab)
- [Attention? Attention!](https://lilianweng.github.io/posts/2018-06-24-attention/)
- [The Transformer Family](https://lilianweng.github.io/posts/2020-04-07-the-transformer-family/) and [Version 2.0](https://lilianweng.github.io/posts/2023-01-27-the-transformer-family-v2/)
- [Large Transformer Model Inference Optimization](https://lilianweng.github.io/posts/2023-01-10-inference-optimization/)
- [The Illustrated Transformer](http://jalammar.github.io/illustrated-transformer/)
- [The Annotated Transformer](https://nlp.seas.harvard.edu/2018/04/03/attention.html)
- [How Transformers work in deep learning and NLP: an intuitive introduction](https://theaisummer.com/transformer/)
- [Transformers from Scratch](https://e2eml.school/transformers.html)
- [Transformers I: Introduction](https://www.borealisai.com/research-blogs/tutorial-14-transformers-i-introduction/), [Transformers II: Extensions](https://www.borealisai.com/research-blogs/tutorial-16-transformers-ii-extensions/) and [Transformers III: Training](https://www.borealisai.com/research-blogs/tutorial-17-transformers-iii-training/)
- [An Intuitive Introduction to Transformers](https://blog.paperspace.com/attention-is-all-you-need-the-components-of-the-transformer/)

#### Transformers: Talks and Tutorials

- Stanford CS25: Transformers United - [2023](https://web.stanford.edu/class/cs25/) - [2021](https://web.stanford.edu/class/cs25/prev_years/2021_fall/) and [Lectures](https://www.youtube.com/playlist?list=PLoROMvodv4rNiJRchCzutFw5ItR_Z27CM)
- [The Huggingface Transformers documentation](https://huggingface.co/course/chapter1/1?fw=pt)
- [Ultimate-Awesome-Transformer-Attention](https://github.com/cmhungsteve/Awesome-Transformer-Attention)
- [Transformers-Tutorials](https://github.com/NielsRogge/Transformers-Tutorials)
- [A study guide to learn about Transformers](https://github.com/dair-ai/Transformers-Recipe)
- [Transformer tutorial by Lucas Beyer](https://www.youtube.com/watch?v=EixI6t5oif0) and [Slides](https://docs.google.com/presentation/d/1ZXFIhYczos679r70Yu8vV9uO6B1J0ztzeDxbnBxD1S0/edit#slide=id.g31364026ad_3_2)
- [Illustrated Guide to Transformers Neural Network: A step by step explanation](https://www.youtube.com/watch?v=4Bdc55j80l8)
- [How a Transformer works at inference vs training time](https://www.youtube.com/watch?v=IGu7ivuy1Ag)

#### Transformers: Libraries

- [xFormers - Toolbox to Accelerate Research on Transformers](https://github.com/facebookresearch/xformers)

### Other Advanced architectures

- [The NLP Cookbook: Modern Recipes for Transformer based Deep Learning Architectures](https://arxiv.org/abs/2104.10640)
